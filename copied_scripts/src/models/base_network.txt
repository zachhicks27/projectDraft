# base_network.py
import torch
import torch.nn as nn
import torch.nn.functional as F

# Constants used across networks
HIDDEN1_UNITS = 40
HIDDEN2_UNITS = 180

class BaseNetwork(nn.Module):
    """Base network with shared components for Actor and Critic"""
    def __init__(self):
        """Initialize base network"""
        super().__init__()
        
        # Shared attention layer that will be used by both Actor and Critic
        self.attention = nn.Sequential(
            nn.Linear(HIDDEN2_UNITS * 2, HIDDEN2_UNITS),
            nn.Tanh(),
            nn.Linear(HIDDEN2_UNITS, 1)
        )
    
    def apply_attention(self, sequence, lengths):
        """
        Apply attention mechanism to sequence
        
        Args:
            sequence: Tensor of shape [batch_size, seq_len, hidden_size]
            lengths: Tensor of shape [batch_size] containing actual sequence lengths
        """
        # Create attention mask
        max_len = sequence.size(1)
        mask = torch.arange(max_len, device=self.device)[None, :] < lengths[:, None]
        mask = mask.float()

        # Calculate attention scores
        attention_weights = self.attention(sequence)
        attention_weights = attention_weights.squeeze(-1)
        attention_weights = attention_weights.masked_fill(~mask.bool(), float('-inf'))
        attention_weights = F.softmax(attention_weights, dim=1)

        # Apply attention to sequence
        attended = torch.bmm(attention_weights.unsqueeze(1), sequence)
        return attended.squeeze(1)
    
    def target_train(self):
        """
        Update target network using soft update
        
        θ_target = τ*θ_local + (1 - τ)*θ_target
        """
        if self.target_network is None:
            return
            
        for target_param, param in zip(self.target_network.parameters(), 
                                     self.parameters()):
            target_param.data.copy_(
                self.tau * param.data + (1.0 - self.tau) * target_param.data
            )
            
    def process_sequences(self, sequences, lengths):
        """Process variable length sequences with masking"""
        if lengths is not None:
            mask = torch.arange(sequences.size(1), device=self.device)[None, :] < lengths[:, None]
            mask = mask.float().unsqueeze(-1)
            masked_seq = sequences * mask
            return masked_seq.sum(dim=1) / lengths.float().unsqueeze(-1).clamp(min=1)
        else:
            return sequences.mean(dim=1)